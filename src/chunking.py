# -*- coding: utf-8 -*-
"""Chunking.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1D_tlQEQ1B2FF_G_gEauUkNp6J8kOHQ7e

# Document Chunking
"""

"""
Text Chunking Module
Implements text chunking for long documents using recursive character splitting
"""
from typing import List, Dict
from langchain_text_splitters import RecursiveCharacterTextSplitter

class DocumentChunker:
    """Handle document chunking with recursive character splitting"""

    def __init__(self, chunk_size: int = 1000, chunk_overlap: int = 200):
        """
        Initialize chunker

        Args:
            chunk_size: Maximum size of each chunk (default: 1000)
            chunk_overlap: Overlap between consecutive chunks (default: 200)
        """
        self.chunk_size = chunk_size
        self.chunk_overlap = chunk_overlap

    def chunk_document(self, document: Dict) -> List[Dict]:
        """
        Chunk a document using recursive character splitting.
        This method keeps paragraphs, sentences, and words together when possible.

        Args:
            document: Document dict with 'text' and 'metadata' keys

        Returns:
            List of chunk dictionaries
        """
        text = document.get('text', '')
        metadata = document.get('metadata', {})

        # Create text splitter
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=self.chunk_size,
            chunk_overlap=self.chunk_overlap,
            length_function=len,
            separators=["\n\n", "\n", ". ", " ", ""]
        )

        # Split text into chunks
        chunks = text_splitter.split_text(text)

        # Create chunk documents with metadata
        chunk_docs = []
        for i, chunk in enumerate(chunks):
            chunk_metadata = metadata.copy() if metadata else {}
            chunk_metadata.update({
                'chunk_id': i,
                'chunk_size': len(chunk)
            })

            chunk_docs.append({
                'text': chunk,
                'metadata': chunk_metadata
            })

        return chunk_docs
